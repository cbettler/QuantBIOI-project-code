{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(%): 90.7348242812\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "#read in dataset\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "labels = df[\"diagnosis\"]\n",
    "df = df.drop(\"diagnosis\",axis=1)\n",
    "\n",
    "\n",
    "#values formatted\n",
    "dfTrn, dfDev, dfTes = numpy.split(df, [int(.15*len(df)), int(.7*len(df))])\n",
    "DTrn, DDev, DTes = numpy.split(labels, [int(.15*len(labels)), int(.7*len(labels))])\n",
    "\n",
    "#run model and test\n",
    "model = rfc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "model_score = model.score(dfDev,DDev)\n",
    "print(\"Accuracy(%):\",model_score*100)\n",
    "\n",
    "#pretty accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 569\n",
      "random forest 0.9271356783919598\n",
      "knn 0.9095477386934674\n",
      "svc(linear) 0.9221105527638191\n",
      "svc(rbf) 0.5678391959798995\n",
      "logistic regression 0.9045226130653267\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pandas_montecarlo\n",
    "from scipy.stats import shapiro, kruskal, f_oneway\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "\n",
    "## RandomForest Classifier with monte carlo simulated training set\n",
    "numpy.random.seed(1234)\n",
    "\n",
    "#df = pd.read_csv(\"mc_test_data.csv\")\n",
    "df = pd.read_csv(\"rndf_filt_data.csv\")\n",
    "#print(df.head())\n",
    "#df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "df = df.drop([\"Unnamed: 0\"],axis=1)\n",
    "df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "\n",
    "#split dataset for mc seed and testing\n",
    "\n",
    "#df_mc, df = numpy.split(df, [int(.7*len(df))])\n",
    "\n",
    "#split dataset by class\n",
    "df_1 = pd.read_csv(\"mc_data_M.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df_0 = pd.read_csv(\"mc_data_B.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "#df_1 = df_mc.loc[df_mc.diagnosis==1]\n",
    "#df_0 = df_mc.loc[df_mc.diagnosis==0]\n",
    "#df_1 = df_1.drop([\"diagnosis\"],axis=1)\n",
    "#df_0 = df_0.drop([\"diagnosis\"],axis=1)\n",
    "\n",
    "#simulate class 0 data\n",
    "mc_sim_df_0 = pd.DataFrame()\n",
    "mc_sim_df_0['diagnosis']= ['0'] * len(df_0.index)\n",
    "for col in df_0.columns:\n",
    "    col_sim = df_0[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_0[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "#simulate class 1 data\n",
    "mc_sim_df_1 = pd.DataFrame()\n",
    "mc_sim_df_1['diagnosis']= ['1'] * len(df_1.index)\n",
    "for col in df_1.columns:\n",
    "    col_sim = df_1[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_1[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "\n",
    "#diag = mc_sim_df_1.append(mc_sim_df_0)['diagnosis']\n",
    "mc_sim_df = mc_sim_df_1.append(mc_sim_df_0)\n",
    "#shuffling dataframe for good luck\n",
    "#mc_sim_df = mc_sim_df.sample(frac=1)\n",
    "#mc_sim_df['diagnosis']=diag\n",
    "print(len(mc_sim_df.index),len(df.index))\n",
    "mc_sim_df.head(20)\n",
    "\n",
    "\n",
    "#values formatted\n",
    "labels = df[\"diagnosis\"]\n",
    "df = df.drop(\"diagnosis\",axis=1)\n",
    "dfDev, dfTes = numpy.split(df, [int(.7*len(df))])\n",
    "DDev, DTes = numpy.split(labels, [int(.7*len(labels))])\n",
    "\n",
    "DTrn =  mc_sim_df['diagnosis']\n",
    "dfTrn = mc_sim_df.drop(['diagnosis'], axis = 1)\n",
    "\n",
    "#run model and test\n",
    "#randomforest\n",
    "model = rfc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"random forest\", hit/len(pd))\n",
    "\n",
    "#knn\n",
    "model = knc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"knn\", hit/len(pd))\n",
    "\n",
    "#svc\n",
    "model = svc(kernel=\"linear\")\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"svc(linear)\", hit/len(pd))\n",
    "\n",
    "#svc\n",
    "model = svc(kernel=\"rbf\")\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"svc(rbf)\", hit/len(pd))\n",
    "\n",
    "#logistic regression\n",
    "model = lgr()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"logistic regression\", hit/len(pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset normality\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "#read in dataset\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "labels = df[\"diagnosis\"]\n",
    "df = df.drop(\"diagnosis\",axis=1)\n",
    "for col in df.columns:\n",
    "    print(col.title(), shapiro(df[col]))\n",
    "        \n",
    "#dataset is normal\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  area_worst  concave.points_mean  concave.points_worst  \\\n",
      "0          21       630.5             0.031100               0.07283   \n",
      "1          22       314.9             0.020760               0.06227   \n",
      "2          38       545.9             0.029230               0.05013   \n",
      "3          47       242.2             0.005917               0.02564   \n",
      "4          49       582.6             0.027490               0.06548   \n",
      "\n",
      "   perimeter_worst  radius_worst  \n",
      "0            96.09        14.500  \n",
      "1            65.13        10.230  \n",
      "2            84.46        13.300  \n",
      "3            57.26         8.964  \n",
      "4            89.88        13.760  \n",
      "   Unnamed: 0  area_worst  concave.points_mean  concave.points_worst  \\\n",
      "0           1      2019.0              0.14710                0.2654   \n",
      "1           3      1709.0              0.12790                0.2430   \n",
      "2           5      1575.0              0.10430                0.1625   \n",
      "3           7      1606.0              0.07400                0.1932   \n",
      "4           8       897.0              0.05985                0.1556   \n",
      "\n",
      "   perimeter_worst  radius_worst  \n",
      "0            184.6         25.38  \n",
      "1            152.5         23.57  \n",
      "2            152.2         22.54  \n",
      "3            153.2         22.88  \n",
      "4            110.6         17.06  \n",
      "   Unnamed: 0 diagnosis  area_worst  concave.points_mean  \\\n",
      "0           2         M      1956.0              0.07017   \n",
      "1           4         M       567.7              0.10520   \n",
      "2           6         M       741.6              0.08089   \n",
      "3          20         B       711.2              0.04781   \n",
      "4          24         M      2615.0              0.08632   \n",
      "\n",
      "   concave.points_worst  perimeter_worst  radius_worst  \n",
      "0                0.1860           158.80         24.99  \n",
      "1                0.2575            98.87         14.91  \n",
      "2                0.1741           103.40         15.47  \n",
      "3                0.1288            99.70         15.11  \n",
      "4                0.2009           188.00         29.17  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "#df1 = pd.read_csv(\"mc_data_B.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df1 = pd.read_csv(\"mc_data_B.csv\")\n",
    "print(df1.head(5))\n",
    "#df2 = pd.read_csv(\"mc_data_M.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df2 = pd.read_csv(\"mc_data_M.csv\")\n",
    "print(df2.head(5))\n",
    "#df3 = pd.read_csv(\"mc_test_data.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df3 = pd.read_csv(\"mc_test_data.csv\")\n",
    "print(df3.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pandas_montecarlo\n",
    "from scipy.stats import shapiro, kruskal, f_oneway\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "\n",
    "## RandomForest Classifier with monte carlo simulated training set\n",
    "numpy.random.seed(1234)\n",
    "\n",
    "#df = pd.read_csv(\"mc_test_data.csv\")\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest 0.9159663865546218\n",
      "knn 0.9243697478991597\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9159663865546218\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pandas_montecarlo\n",
    "from scipy.stats import shapiro, kruskal, f_oneway\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "\n",
    "## RandomForest Classifier with monte carlo simulated training set\n",
    "numpy.random.seed(1234)\n",
    "\n",
    "#df = pd.read_csv(\"mc_test_data.csv\")\n",
    "#df = pd.read_csv(\"rndf_filt_data.csv\")\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "#random forest selected the following columns as most predictive\n",
    "df = df[['diagnosis','area_worst','concave points_mean','concave points_worst','perimeter_worst','radius_worst']]\n",
    "\n",
    "#print(df.head())\n",
    "#df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "#df = df.drop([\"Unnamed: 0\"],axis=1)\n",
    "df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "\n",
    "#split dataset for mc seed and testing\n",
    "\n",
    "df_mc, df = numpy.split(df, [int(.7*len(df))])\n",
    "\n",
    "#split dataset by class\n",
    "#df_1 = pd.read_csv(\"mc_data_M.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "#df_0 = pd.read_csv(\"mc_data_B.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df_1 = df_mc.loc[df_mc.diagnosis==1]\n",
    "df_0 = df_mc.loc[df_mc.diagnosis==0]\n",
    "df_1 = df_1.drop([\"diagnosis\"],axis=1)\n",
    "df_0 = df_0.drop([\"diagnosis\"],axis=1)\n",
    "\n",
    "#simulate class 0 data\n",
    "mc_sim_df_0 = pd.DataFrame()\n",
    "mc_sim_df_0['diagnosis']= ['0'] * len(df_0.index)\n",
    "for col in df_0.columns:\n",
    "    col_sim = df_0[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_0[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "#simulate class 1 data\n",
    "mc_sim_df_1 = pd.DataFrame()\n",
    "mc_sim_df_1['diagnosis']= ['1'] * len(df_1.index)\n",
    "for col in df_1.columns:\n",
    "    col_sim = df_1[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_1[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "\n",
    "#diag = mc_sim_df_1.append(mc_sim_df_0)['diagnosis']\n",
    "mc_sim_df = mc_sim_df_1.append(mc_sim_df_0)\n",
    "#shuffling dataframe for good luck\n",
    "#mc_sim_df = mc_sim_df.sample(frac=1)\n",
    "#mc_sim_df['diagnosis']=diag\n",
    "mc_sim_df.head(20)\n",
    "\n",
    "\n",
    "#values formatted\n",
    "labels = df[\"diagnosis\"]\n",
    "df = df.drop(\"diagnosis\",axis=1)\n",
    "dfDev, dfTes = numpy.split(df, [int(.7*len(df))])\n",
    "DDev, DTes = numpy.split(labels, [int(.7*len(labels))])\n",
    "\n",
    "DTrn =  mc_sim_df['diagnosis']\n",
    "dfTrn = mc_sim_df.drop(['diagnosis'], axis = 1)\n",
    "\n",
    "#run model and test\n",
    "#randomforest\n",
    "model = rfc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"random forest\", hit/len(pd))\n",
    "\n",
    "#knn\n",
    "model = knc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"knn\", hit/len(pd))\n",
    "\n",
    "#svc\n",
    "model = svc(kernel=\"linear\")\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"svc(linear)\", hit/len(pd))\n",
    "\n",
    "#svc\n",
    "model = svc(kernel=\"rbf\")\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"svc(rbf)\", hit/len(pd))\n",
    "\n",
    "#logistic regression\n",
    "model = lgr()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"logistic regression\", hit/len(pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pandas_montecarlo\n",
    "from scipy.stats import shapiro, kruskal, f_oneway\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "\n",
    "## RandomForest Classifier with monte carlo simulated training set\n",
    "numpy.random.seed(1234)\n",
    "\n",
    "#df = pd.read_csv(\"mc_test_data.csv\")\n",
    "#df = pd.read_csv(\"rndf_filt_data.csv\")\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "#random forest selected the following columns as most predictive\n",
    "df = df[['diagnosis','area_worst','concave points_mean','concave points_worst','perimeter_worst','radius_worst']]\n",
    "\n",
    "#print(df.head())\n",
    "#df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "#df = df.drop([\"Unnamed: 0\"],axis=1)\n",
    "df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "\n",
    "#split dataset for mc seed and testing\n",
    "\n",
    "df_mc, df = numpy.split(df, [int(.7*len(df))])\n",
    "\n",
    "#split dataset by class\n",
    "#df_1 = pd.read_csv(\"mc_data_M.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "#df_0 = pd.read_csv(\"mc_data_B.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df_1 = df_mc.loc[df_mc.diagnosis==1]\n",
    "df_0 = df_mc.loc[df_mc.diagnosis==0]\n",
    "df_1 = df_1.drop([\"diagnosis\"],axis=1)\n",
    "df_0 = df_0.drop([\"diagnosis\"],axis=1)\n",
    "\n",
    "#simulate class 0 data\n",
    "mc_sim_df_0 = pd.DataFrame()\n",
    "mc_sim_df_0['diagnosis']= ['0'] * len(df_0.index)\n",
    "for col in df_0.columns:\n",
    "    col_sim = df_0[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_0[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "#simulate class 1 data\n",
    "mc_sim_df_1 = pd.DataFrame()\n",
    "mc_sim_df_1['diagnosis']= ['1'] * len(df_1.index)\n",
    "for col in df_1.columns:\n",
    "    col_sim = df_1[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_1[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "\n",
    "#diag = mc_sim_df_1.append(mc_sim_df_0)['diagnosis']\n",
    "mc_sim_df = mc_sim_df_1.append(mc_sim_df_0)\n",
    "#shuffling dataframe for good luck\n",
    "#mc_sim_df = mc_sim_df.sample(frac=1)\n",
    "#mc_sim_df['diagnosis']=diag\n",
    "mc_sim_df.head(20)\n",
    "\n",
    "\n",
    "#values formatted\n",
    "labels = df[\"diagnosis\"]\n",
    "df = df.drop(\"diagnosis\",axis=1)\n",
    "dfDev, dfTes = numpy.split(df, [int(.7*len(df))])\n",
    "DDev, DTes = numpy.split(labels, [int(.7*len(labels))])\n",
    "\n",
    "#DTrn =  mc_sim_df['diagnosis']\n",
    "#dfTrn = mc_sim_df.drop(['diagnosis'], axis = 1)\n",
    "DTrn =  df_mc['diagnosis']\n",
    "dfTrn = df_mc.drop(['diagnosis'], axis = 1)\n",
    "\n",
    "#run model and test\n",
    "#randomforest\n",
    "model = rfc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"random forest\", hit/len(pd))\n",
    "\n",
    "#knn\n",
    "model = knc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"knn\", hit/len(pd))\n",
    "\n",
    "#svc\n",
    "model = svc(kernel=\"linear\")\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"svc(linear)\", hit/len(pd))\n",
    "\n",
    "#svc\n",
    "model = svc(kernel=\"rbf\")\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"svc(rbf)\", hit/len(pd))\n",
    "\n",
    "#logistic regression\n",
    "model = lgr()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"logistic regression\", hit/len(pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9243697478991597\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 1\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 2\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 3\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 4\n",
      "random forest 0.9663865546218487\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9327731092436975\n",
      "knn 0.8739495798319328\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 5\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9327731092436975\n",
      "knn 0.8823529411764706\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 6\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9327731092436975\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 7\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 8\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.8991596638655462\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9411764705882353\n",
      "done\n",
      "iter 9\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9327731092436975\n",
      "knn 0.8907563025210085\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9159663865546218\n",
      "done\n",
      "iter 10\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9243697478991597\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7394957983193278\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 11\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9411764705882353\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.907563025210084\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 12\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.907563025210084\n",
      "knn 0.8907563025210085\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 13\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.907563025210084\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 14\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9327731092436975\n",
      "knn 0.8823529411764706\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 15\n",
      "random forest 0.9663865546218487\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.907563025210084\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 16\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.8823529411764706\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 17\n",
      "random forest 0.957983193277311\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.907563025210084\n",
      "knn 0.8739495798319328\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 18\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.907563025210084\n",
      "knn 0.9243697478991597\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 19\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8907563025210085\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 20\n",
      "random forest 0.957983193277311\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9327731092436975\n",
      "knn 0.8823529411764706\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 21\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9495798319327731\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7478991596638656\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 22\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 23\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8823529411764706\n",
      "svc(linear) 0.907563025210084\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9411764705882353\n",
      "done\n",
      "iter 24\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.8907563025210085\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 25\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9411764705882353\n",
      "knn 0.907563025210084\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 26\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.907563025210084\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 27\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9495798319327731\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 28\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9243697478991597\n",
      "svc(linear) 0.907563025210084\n",
      "svc(rbf) 0.7815126050420168\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 29\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 30\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8907563025210085\n",
      "knn 0.8823529411764706\n",
      "svc(linear) 0.8487394957983193\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 31\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9243697478991597\n",
      "knn 0.8907563025210085\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 32\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.907563025210084\n",
      "knn 0.8739495798319328\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 33\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 34\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9243697478991597\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 35\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 36\n",
      "random forest 0.957983193277311\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 37\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9243697478991597\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.8823529411764706\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 38\n",
      "random forest 0.957983193277311\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 39\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.907563025210084\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.907563025210084\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 40\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9243697478991597\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 41\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 42\n",
      "random forest 0.907563025210084\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 43\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8907563025210085\n",
      "knn 0.8571428571428571\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 44\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9327731092436975\n",
      "knn 0.907563025210084\n",
      "svc(linear) 0.907563025210084\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 45\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.907563025210084\n",
      "knn 0.8823529411764706\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 46\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.907563025210084\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 47\n",
      "random forest 0.8991596638655462\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9495798319327731\n",
      "knn 0.8823529411764706\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 48\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9411764705882353\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 49\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 50\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 51\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9327731092436975\n",
      "knn 0.8823529411764706\n",
      "svc(linear) 0.8823529411764706\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 53\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.957983193277311\n",
      "knn 0.907563025210084\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 54\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8823529411764706\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 55\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.907563025210084\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 56\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9243697478991597\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 57\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9243697478991597\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 58\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.907563025210084\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.907563025210084\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 59\n",
      "random forest 0.9159663865546218\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8907563025210085\n",
      "knn 0.9243697478991597\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 60\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.8907563025210085\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 61\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.907563025210084\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 62\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.907563025210084\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9411764705882353\n",
      "done\n",
      "iter 63\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9495798319327731\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.907563025210084\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 64\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8907563025210085\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 65\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8907563025210085\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 66\n",
      "random forest 0.8907563025210085\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8907563025210085\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 67\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9327731092436975\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7815126050420168\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 68\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9243697478991597\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.8991596638655462\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 69\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9411764705882353\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 70\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9243697478991597\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 71\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 72\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9243697478991597\n",
      "knn 0.9243697478991597\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 73\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 74\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9243697478991597\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.8823529411764706\n",
      "svc(rbf) 0.7394957983193278\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 75\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8907563025210085\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 76\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9411764705882353\n",
      "knn 0.907563025210084\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 77\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8907563025210085\n",
      "svc(linear) 0.8823529411764706\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 78\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 79\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8823529411764706\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7478991596638656\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 80\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.907563025210084\n",
      "knn 0.9243697478991597\n",
      "svc(linear) 0.8991596638655462\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9411764705882353\n",
      "done\n",
      "iter 81\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.907563025210084\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.8823529411764706\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 82\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 83\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9327731092436975\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 84\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9411764705882353\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 85\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.8991596638655462\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 86\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.907563025210084\n",
      "knn 0.8739495798319328\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 87\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 88\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9411764705882353\n",
      "done\n",
      "iter 89\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 90\n",
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.865546218487395\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 91\n",
      "random forest 0.9495798319327731\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.907563025210084\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 92\n",
      "random forest 0.8991596638655462\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 93\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9327731092436975\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7394957983193278\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 94\n",
      "random forest 0.9327731092436975\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.865546218487395\n",
      "knn 0.8823529411764706\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 95\n",
      "random forest 0.9159663865546218\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.907563025210084\n",
      "knn 0.9159663865546218\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n",
      "iter 96\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9243697478991597\n",
      "knn 0.9411764705882353\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7563025210084033\n",
      "logistic regression 0.9411764705882353\n",
      "done\n",
      "iter 97\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.8319327731092437\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 98\n",
      "random forest 0.9411764705882353\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.9159663865546218\n",
      "knn 0.9327731092436975\n",
      "svc(linear) 0.8739495798319328\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9243697478991597\n",
      "done\n",
      "iter 99\n",
      "random forest 0.957983193277311\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n",
      "random forest 0.8991596638655462\n",
      "knn 0.8907563025210085\n",
      "svc(linear) 0.8823529411764706\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9327731092436975\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pandas_montecarlo\n",
    "from scipy.stats import shapiro, kruskal, f_oneway\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "def classify(s):\n",
    "    import pandas as pd\n",
    "    import numpy\n",
    "    import pandas_montecarlo\n",
    "    from scipy.stats import shapiro, kruskal, f_oneway\n",
    "    from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "    from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "    from sklearn.svm import SVC as svc\n",
    "    from sklearn.linear_model import LogisticRegression as lgr\n",
    "    ## RandomForest Classifier with monte carlo simulated training set\n",
    "    numpy.random.seed(s)\n",
    "\n",
    "    #df = pd.read_csv(\"mc_test_data.csv\")\n",
    "    #df = pd.read_csv(\"rndf_filt_data.csv\")\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "    #random forest selected the following columns as most predictive\n",
    "    df = df[['diagnosis','area_worst','concave points_mean','concave points_worst','perimeter_worst','radius_worst']]\n",
    "\n",
    "    #print(df.head())\n",
    "    #df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "    #df = df.drop([\"Unnamed: 0\"],axis=1)\n",
    "    df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "    df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "\n",
    "    #split dataset for mc seed and testing\n",
    "\n",
    "    df_mc, df = numpy.split(df, [int(.7*len(df))])\n",
    "\n",
    "    #split dataset by class\n",
    "    #df_1 = pd.read_csv(\"mc_data_M.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "    #df_0 = pd.read_csv(\"mc_data_B.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "    df_1 = df_mc.loc[df_mc.diagnosis==1]\n",
    "    df_0 = df_mc.loc[df_mc.diagnosis==0]\n",
    "    df_1 = df_1.drop([\"diagnosis\"],axis=1)\n",
    "    df_0 = df_0.drop([\"diagnosis\"],axis=1)\n",
    "\n",
    "    #simulate class 0 data\n",
    "    mc_sim_df_0 = pd.DataFrame()\n",
    "    mc_sim_df_0['diagnosis']= ['0'] * len(df_0.index)\n",
    "    for col in df_0.columns:\n",
    "        col_sim = df_0[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "        col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "        for col2 in col_sim.columns:\n",
    "            mc_sim_df_0[col]=col_sim[col2]\n",
    "            #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "                #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "            #else:\n",
    "                #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "    #simulate class 1 data\n",
    "    mc_sim_df_1 = pd.DataFrame()\n",
    "    mc_sim_df_1['diagnosis']= ['1'] * len(df_1.index)\n",
    "    for col in df_1.columns:\n",
    "        col_sim = df_1[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "        col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "        for col2 in col_sim.columns:\n",
    "            mc_sim_df_1[col]=col_sim[col2]\n",
    "            #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "                #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "            #else:\n",
    "                #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "\n",
    "    #diag = mc_sim_df_1.append(mc_sim_df_0)['diagnosis']\n",
    "    mc_sim_df = mc_sim_df_1.append(mc_sim_df_0)\n",
    "    #shuffling dataframe for good luck\n",
    "    #mc_sim_df = mc_sim_df.sample(frac=1)\n",
    "    #mc_sim_df['diagnosis']=diag\n",
    "    mc_sim_df.head(20)\n",
    "\n",
    "\n",
    "    #values formatted\n",
    "    labels = df[\"diagnosis\"]\n",
    "    df = df.drop(\"diagnosis\",axis=1)\n",
    "    dfDev, dfTes = numpy.split(df, [int(.7*len(df))])\n",
    "    DDev, DTes = numpy.split(labels, [int(.7*len(labels))])\n",
    "\n",
    "    #DTrn =  mc_sim_df['diagnosis']\n",
    "    #dfTrn = mc_sim_df.drop(['diagnosis'], axis = 1)\n",
    "    DTrn =  df_mc['diagnosis']\n",
    "    dfTrn = df_mc.drop(['diagnosis'], axis = 1)\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    #run model and test\n",
    "    #randomforest\n",
    "    model = rfc()\n",
    "    model = model.fit(dfTrn.values,DTrn)\n",
    "    pd = model.predict(dfDev)\n",
    "    hit = 0\n",
    "    for i in range(len(pd)):\n",
    "        if(int(pd[i])==int(DDev.iloc[i])):\n",
    "            hit+=1\n",
    "    scores.append(hit/len(pd))\n",
    "    print(\"random forest\", hit/len(pd))\n",
    "\n",
    "    #knn\n",
    "    model = knc()\n",
    "    model = model.fit(dfTrn.values,DTrn)\n",
    "    pd = model.predict(dfDev)\n",
    "    hit = 0\n",
    "    for i in range(len(pd)):\n",
    "        if(int(pd[i])==int(DDev.iloc[i])):\n",
    "            hit+=1\n",
    "    scores.append(hit/len(pd))\n",
    "    print(\"knn\", hit/len(pd))\n",
    "\n",
    "    #svc\n",
    "    model = svc(kernel=\"linear\")\n",
    "    model = model.fit(dfTrn.values,DTrn)\n",
    "    pd = model.predict(dfDev)\n",
    "    hit = 0\n",
    "    for i in range(len(pd)):\n",
    "        if(int(pd[i])==int(DDev.iloc[i])):\n",
    "            hit+=1\n",
    "    scores.append(hit/len(pd))\n",
    "    print(\"svc(linear)\", hit/len(pd))\n",
    "\n",
    "    #svc\n",
    "    model = svc(kernel=\"rbf\")\n",
    "    model = model.fit(dfTrn.values,DTrn)\n",
    "    pd = model.predict(dfDev)\n",
    "    hit = 0\n",
    "    for i in range(len(pd)):\n",
    "        if(int(pd[i])==int(DDev.iloc[i])):\n",
    "            hit+=1\n",
    "    scores.append(hit/len(pd))\n",
    "    print(\"svc(rbf)\", hit/len(pd))\n",
    "\n",
    "    #logistic regression\n",
    "    model = lgr()\n",
    "    model = model.fit(dfTrn.values,DTrn)\n",
    "    pd = model.predict(dfDev)\n",
    "    hit = 0\n",
    "    for i in range(len(pd)):\n",
    "        if(int(pd[i])==int(DDev.iloc[i])):\n",
    "            hit+=1\n",
    "    scores.append(hit/len(pd))\n",
    "    print(\"logistic regression\", hit/len(pd))\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def classify_mc(s):\n",
    "    import pandas as pd\n",
    "    import numpy\n",
    "    import pandas_montecarlo\n",
    "    from scipy.stats import shapiro, kruskal, f_oneway\n",
    "    from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "    from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "    from sklearn.svm import SVC as svc\n",
    "    from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "    ## RandomForest Classifier with monte carlo simulated training set\n",
    "    numpy.random.seed(s)\n",
    "\n",
    "    #df = pd.read_csv(\"mc_test_data.csv\")\n",
    "    #df = pd.read_csv(\"rndf_filt_data.csv\")\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "    #random forest selected the following columns as most predictive\n",
    "    df = df[['diagnosis','area_worst','concave points_mean','concave points_worst','perimeter_worst','radius_worst']]\n",
    "\n",
    "    #print(df.head())\n",
    "    #df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "    #df = df.drop([\"Unnamed: 0\"],axis=1)\n",
    "    df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "    df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "\n",
    "    #split dataset for mc seed and testing\n",
    "\n",
    "    df_mc, df = numpy.split(df, [int(.7*len(df))])\n",
    "\n",
    "    #split dataset by class\n",
    "    #df_1 = pd.read_csv(\"mc_data_M.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "    #df_0 = pd.read_csv(\"mc_data_B.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "    df_1 = df_mc.loc[df_mc.diagnosis==1]\n",
    "    df_0 = df_mc.loc[df_mc.diagnosis==0]\n",
    "    df_1 = df_1.drop([\"diagnosis\"],axis=1)\n",
    "    df_0 = df_0.drop([\"diagnosis\"],axis=1)\n",
    "\n",
    "    #simulate class 0 data\n",
    "    mc_sim_df_0 = pd.DataFrame()\n",
    "    mc_sim_df_0['diagnosis']= ['0'] * len(df_0.index)\n",
    "    for col in df_0.columns:\n",
    "        col_sim = df_0[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "        col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "        for col2 in col_sim.columns:\n",
    "            mc_sim_df_0[col]=col_sim[col2]\n",
    "            #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "                #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "            #else:\n",
    "                #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "    #simulate class 1 data\n",
    "    mc_sim_df_1 = pd.DataFrame()\n",
    "    mc_sim_df_1['diagnosis']= ['1'] * len(df_1.index)\n",
    "    for col in df_1.columns:\n",
    "        col_sim = df_1[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "        col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "        for col2 in col_sim.columns:\n",
    "            mc_sim_df_1[col]=col_sim[col2]\n",
    "            #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "                #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "            #else:\n",
    "                #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "\n",
    "    #diag = mc_sim_df_1.append(mc_sim_df_0)['diagnosis']\n",
    "    mc_sim_df = mc_sim_df_1.append(mc_sim_df_0)\n",
    "    #shuffling dataframe for good luck\n",
    "    #mc_sim_df = mc_sim_df.sample(frac=1)\n",
    "    #mc_sim_df['diagnosis']=diag\n",
    "    mc_sim_df.head(20)\n",
    "\n",
    "\n",
    "    #values formatted\n",
    "    labels = df[\"diagnosis\"]\n",
    "    df = df.drop(\"diagnosis\",axis=1)\n",
    "    dfDev, dfTes = numpy.split(df, [int(.7*len(df))])\n",
    "    DDev, DTes = numpy.split(labels, [int(.7*len(labels))])\n",
    "\n",
    "    DTrn =  mc_sim_df['diagnosis']\n",
    "    dfTrn = mc_sim_df.drop(['diagnosis'], axis = 1)\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    #run model and test\n",
    "    #randomforest\n",
    "    model = rfc()\n",
    "    model = model.fit(dfTrn.values,DTrn)\n",
    "    pd = model.predict(dfDev)\n",
    "    hit = 0\n",
    "    for i in range(len(pd)):\n",
    "        if(int(pd[i])==int(DDev.iloc[i])):\n",
    "            hit+=1\n",
    "    scores.append(hit/len(pd))\n",
    "    print(\"random forest\", hit/len(pd))\n",
    "\n",
    "    #knn\n",
    "    model = knc()\n",
    "    model = model.fit(dfTrn.values,DTrn)\n",
    "    pd = model.predict(dfDev)\n",
    "    hit = 0\n",
    "    for i in range(len(pd)):\n",
    "        if(int(pd[i])==int(DDev.iloc[i])):\n",
    "            hit+=1\n",
    "    scores.append(hit/len(pd))\n",
    "    print(\"knn\", hit/len(pd))\n",
    "\n",
    "    #svc\n",
    "    model = svc(kernel=\"linear\")\n",
    "    model = model.fit(dfTrn.values,DTrn)\n",
    "    pd = model.predict(dfDev)\n",
    "    hit = 0\n",
    "    for i in range(len(pd)):\n",
    "        if(int(pd[i])==int(DDev.iloc[i])):\n",
    "            hit+=1\n",
    "    scores.append(hit/len(pd))\n",
    "    print(\"svc(linear)\", hit/len(pd))\n",
    "\n",
    "    #svc\n",
    "    model = svc(kernel=\"rbf\")\n",
    "    model = model.fit(dfTrn.values,DTrn)\n",
    "    pd = model.predict(dfDev)\n",
    "    hit = 0\n",
    "    for i in range(len(pd)):\n",
    "        if(int(pd[i])==int(DDev.iloc[i])):\n",
    "            hit+=1\n",
    "    scores.append(hit/len(pd))\n",
    "    print(\"svc(rbf)\", hit/len(pd))\n",
    "\n",
    "    #logistic regression\n",
    "    model = lgr()\n",
    "    model = model.fit(dfTrn.values,DTrn)\n",
    "    pd = model.predict(dfDev)\n",
    "    hit = 0\n",
    "    for i in range(len(pd)):\n",
    "        if(int(pd[i])==int(DDev.iloc[i])):\n",
    "            hit+=1\n",
    "    scores.append(hit/len(pd))\n",
    "    print(\"logistic regression\", hit/len(pd))\n",
    "    \n",
    "    return scores\n",
    "\n",
    "scoresets = []\n",
    "scoresets_mc = []\n",
    "seed = 1000\n",
    "scoresets.append(classify(seed))\n",
    "scoresets_mc.append(classify_mc(seed))\n",
    "seed+=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pandas_montecarlo\n",
    "from scipy.stats import shapiro, kruskal, f_oneway\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "dframe = pd.DataFrame(scoresets,columns=[\"random_forest\",'knn','svc(linear)','svc(rbf)','logistic_regression'])\n",
    "dframe_mc = pd.DataFrame(scoresets_mc,columns=[\"random_forest\",'knn','svc(linear)','svc(rbf)','logistic_regression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n",
      "(0.9278914332389832, 3.785988883464597e-05)\n",
      "(0.950848400592804, 0.0009439075947739184)\n",
      "F_onewayResult(statistic=103.26701708278591, pvalue=8.6125469152935763e-20)\n",
      "KruskalResult(statistic=72.311610643421531, pvalue=1.8376303214443742e-17)\n",
      "0.93731092437\n",
      "0.916134453782\n",
      "knn\n",
      "(1.0, 1.0)\n",
      "(0.9454075694084167, 0.0004185369180049747)\n",
      "F_onewayResult(statistic=345.27066960075445, pvalue=2.8411559022891192e-45)\n",
      "KruskalResult(statistic=152.34073595320169, pvalue=5.3377234089233228e-35)\n",
      "0.865546218487\n",
      "0.908907563025\n",
      "svc(linear)\n",
      "(1.0, 1.0)\n",
      "(0.8508269786834717, 1.272462046841838e-08)\n",
      "F_onewayResult(statistic=112.79612105312539, pvalue=3.8387325169777265e-21)\n",
      "KruskalResult(statistic=83.174494205064036, pvalue=7.5120749762869016e-20)\n",
      "0.890756302521\n",
      "0.874705882353\n",
      "svc(rbf)\n",
      "(1.0, 1.0)\n",
      "(0.737356424331665, 4.393760529020074e-12)\n",
      "F_onewayResult(statistic=222.75000000000327, pvalue=3.0249511931027103e-34)\n",
      "KruskalResult(statistic=146.52497037019828, pvalue=9.9672689757676211e-34)\n",
      "0.773109243697\n",
      "0.763025210084\n",
      "logistic_regression\n",
      "(1.0, 1.0)\n",
      "(0.7632851600646973, 2.133442381091477e-11)\n",
      "F_onewayResult(statistic=5221.2004626059952, pvalue=2.9602381242658911e-144)\n",
      "KruskalResult(statistic=175.76803565529679, pvalue=4.0690167564908745e-40)\n",
      "0.890756302521\n",
      "0.928823529412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/scipy/stats/morestats.py:1323: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "#print(dframe.head())\n",
    "#print(dframe_mc.head())\n",
    "for col in dframe.columns:\n",
    "    print(col)\n",
    "    print(shapiro(dframe[col]))\n",
    "    print(shapiro(dframe_mc[col]))\n",
    "    print(f_oneway(dframe[col],dframe_mc[col]))\n",
    "    print(kruskal(dframe[col],dframe_mc[col]))\n",
    "    print(statistics.mean(dframe[col]))\n",
    "    print(statistics.mean(dframe_mc[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pandas_montecarlo\n",
    "from scipy.stats import shapiro, kruskal, f_oneway\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "## RandomForest Classifier with monte carlo simulated training set\n",
    "numpy.random.seed(1234)\n",
    "\n",
    "#df = pd.read_csv(\"mc_test_data.csv\")\n",
    "#df = pd.read_csv(\"rndf_filt_data.csv\")\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "#random forest selected the following columns as most predictive\n",
    "df = df[['diagnosis','area_worst','concave points_mean','concave points_worst','perimeter_worst','radius_worst']]\n",
    "\n",
    "#print(df.head())\n",
    "#df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "#df = df.drop([\"Unnamed: 0\"],axis=1)\n",
    "df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "\n",
    "#split dataset for mc seed and testing\n",
    "\n",
    "df_mc, df = numpy.split(df, [int(.7*len(df))])\n",
    "\n",
    "#split dataset by class\n",
    "#df_1 = pd.read_csv(\"mc_data_M.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "#df_0 = pd.read_csv(\"mc_data_B.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df_1 = df_mc.loc[df_mc.diagnosis==1]\n",
    "df_0 = df_mc.loc[df_mc.diagnosis==0]\n",
    "df_1 = df_1.drop([\"diagnosis\"],axis=1)\n",
    "df_0 = df_0.drop([\"diagnosis\"],axis=1)\n",
    "\n",
    "#simulate class 0 data\n",
    "mc_sim_df_0 = pd.DataFrame()\n",
    "mc_sim_df_0['diagnosis']= ['0'] * len(df_0.index)\n",
    "for col in df_0.columns:\n",
    "    col_sim = df_0[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_0[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "#simulate class 1 data\n",
    "mc_sim_df_1 = pd.DataFrame()\n",
    "mc_sim_df_1['diagnosis']= ['1'] * len(df_1.index)\n",
    "for col in df_1.columns:\n",
    "    col_sim = df_1[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_1[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "\n",
    "#diag = mc_sim_df_1.append(mc_sim_df_0)['diagnosis']\n",
    "mc_sim_df = mc_sim_df_1.append(mc_sim_df_0)\n",
    "#shuffling dataframe for good luck\n",
    "#mc_sim_df = mc_sim_df.sample(frac=1)\n",
    "#mc_sim_df['diagnosis']=diag\n",
    "mc_sim_df.head(20)\n",
    "\n",
    "\n",
    "#values formatted\n",
    "labels = df[\"diagnosis\"]\n",
    "df = df.drop(\"diagnosis\",axis=1)\n",
    "dfDev, dfTes = numpy.split(df, [int(.7*len(df))])\n",
    "DDev, DTes = numpy.split(labels, [int(.7*len(labels))])\n",
    "\n",
    "DTrn =  mc_sim_df['diagnosis']\n",
    "dfTrn = mc_sim_df.drop(['diagnosis'], axis = 1)\n",
    "\n",
    "mc_sim_df.to_csv('mc_sim.csv')\n",
    "df_mc.to_csv('original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
