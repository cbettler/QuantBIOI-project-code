{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(%): 90.7348242812\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "#read in dataset\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "labels = df[\"diagnosis\"]\n",
    "df = df.drop(\"diagnosis\",axis=1)\n",
    "\n",
    "\n",
    "#values formatted\n",
    "dfTrn, dfDev, dfTes = numpy.split(df, [int(.15*len(df)), int(.7*len(df))])\n",
    "DTrn, DDev, DTes = numpy.split(labels, [int(.15*len(labels)), int(.7*len(labels))])\n",
    "\n",
    "#run model and test\n",
    "model = rfc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "model_score = model.score(dfDev,DDev)\n",
    "print(\"Accuracy(%):\",model_score*100)\n",
    "\n",
    "#pretty accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 569\n",
      "random forest 0.9271356783919598\n",
      "knn 0.9095477386934674\n",
      "svc(linear) 0.9221105527638191\n",
      "svc(rbf) 0.5678391959798995\n",
      "logistic regression 0.9045226130653267\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pandas_montecarlo\n",
    "from scipy.stats import shapiro, kruskal, f_oneway\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "\n",
    "## RandomForest Classifier with monte carlo simulated training set\n",
    "numpy.random.seed(1234)\n",
    "\n",
    "#df = pd.read_csv(\"mc_test_data.csv\")\n",
    "df = pd.read_csv(\"rndf_filt_data.csv\")\n",
    "#print(df.head())\n",
    "#df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "df = df.drop([\"Unnamed: 0\"],axis=1)\n",
    "df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "\n",
    "#split dataset for mc seed and testing\n",
    "\n",
    "#df_mc, df = numpy.split(df, [int(.7*len(df))])\n",
    "\n",
    "#split dataset by class\n",
    "df_1 = pd.read_csv(\"mc_data_M.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df_0 = pd.read_csv(\"mc_data_B.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "#df_1 = df_mc.loc[df_mc.diagnosis==1]\n",
    "#df_0 = df_mc.loc[df_mc.diagnosis==0]\n",
    "#df_1 = df_1.drop([\"diagnosis\"],axis=1)\n",
    "#df_0 = df_0.drop([\"diagnosis\"],axis=1)\n",
    "\n",
    "#simulate class 0 data\n",
    "mc_sim_df_0 = pd.DataFrame()\n",
    "mc_sim_df_0['diagnosis']= ['0'] * len(df_0.index)\n",
    "for col in df_0.columns:\n",
    "    col_sim = df_0[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_0[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "#simulate class 1 data\n",
    "mc_sim_df_1 = pd.DataFrame()\n",
    "mc_sim_df_1['diagnosis']= ['1'] * len(df_1.index)\n",
    "for col in df_1.columns:\n",
    "    col_sim = df_1[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_1[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "\n",
    "#diag = mc_sim_df_1.append(mc_sim_df_0)['diagnosis']\n",
    "mc_sim_df = mc_sim_df_1.append(mc_sim_df_0)\n",
    "#shuffling dataframe for good luck\n",
    "#mc_sim_df = mc_sim_df.sample(frac=1)\n",
    "#mc_sim_df['diagnosis']=diag\n",
    "print(len(mc_sim_df.index),len(df.index))\n",
    "mc_sim_df.head(20)\n",
    "\n",
    "\n",
    "#values formatted\n",
    "labels = df[\"diagnosis\"]\n",
    "df = df.drop(\"diagnosis\",axis=1)\n",
    "dfDev, dfTes = numpy.split(df, [int(.7*len(df))])\n",
    "DDev, DTes = numpy.split(labels, [int(.7*len(labels))])\n",
    "\n",
    "DTrn =  mc_sim_df['diagnosis']\n",
    "dfTrn = mc_sim_df.drop(['diagnosis'], axis = 1)\n",
    "\n",
    "#run model and test\n",
    "#randomforest\n",
    "model = rfc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"random forest\", hit/len(pd))\n",
    "\n",
    "#knn\n",
    "model = knc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"knn\", hit/len(pd))\n",
    "\n",
    "#svc\n",
    "model = svc(kernel=\"linear\")\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"svc(linear)\", hit/len(pd))\n",
    "\n",
    "#svc\n",
    "model = svc(kernel=\"rbf\")\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"svc(rbf)\", hit/len(pd))\n",
    "\n",
    "#logistic regression\n",
    "model = lgr()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"logistic regression\", hit/len(pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset normality\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "#read in dataset\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "labels = df[\"diagnosis\"]\n",
    "df = df.drop(\"diagnosis\",axis=1)\n",
    "for col in df.columns:\n",
    "    print(col.title(), shapiro(df[col]))\n",
    "        \n",
    "#dataset is normal\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  area_worst  concave.points_mean  concave.points_worst  \\\n",
      "0          21       630.5             0.031100               0.07283   \n",
      "1          22       314.9             0.020760               0.06227   \n",
      "2          38       545.9             0.029230               0.05013   \n",
      "3          47       242.2             0.005917               0.02564   \n",
      "4          49       582.6             0.027490               0.06548   \n",
      "\n",
      "   perimeter_worst  radius_worst  \n",
      "0            96.09        14.500  \n",
      "1            65.13        10.230  \n",
      "2            84.46        13.300  \n",
      "3            57.26         8.964  \n",
      "4            89.88        13.760  \n",
      "   Unnamed: 0  area_worst  concave.points_mean  concave.points_worst  \\\n",
      "0           1      2019.0              0.14710                0.2654   \n",
      "1           3      1709.0              0.12790                0.2430   \n",
      "2           5      1575.0              0.10430                0.1625   \n",
      "3           7      1606.0              0.07400                0.1932   \n",
      "4           8       897.0              0.05985                0.1556   \n",
      "\n",
      "   perimeter_worst  radius_worst  \n",
      "0            184.6         25.38  \n",
      "1            152.5         23.57  \n",
      "2            152.2         22.54  \n",
      "3            153.2         22.88  \n",
      "4            110.6         17.06  \n",
      "   Unnamed: 0 diagnosis  area_worst  concave.points_mean  \\\n",
      "0           2         M      1956.0              0.07017   \n",
      "1           4         M       567.7              0.10520   \n",
      "2           6         M       741.6              0.08089   \n",
      "3          20         B       711.2              0.04781   \n",
      "4          24         M      2615.0              0.08632   \n",
      "\n",
      "   concave.points_worst  perimeter_worst  radius_worst  \n",
      "0                0.1860           158.80         24.99  \n",
      "1                0.2575            98.87         14.91  \n",
      "2                0.1741           103.40         15.47  \n",
      "3                0.1288            99.70         15.11  \n",
      "4                0.2009           188.00         29.17  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "#df1 = pd.read_csv(\"mc_data_B.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df1 = pd.read_csv(\"mc_data_B.csv\")\n",
    "print(df1.head(5))\n",
    "#df2 = pd.read_csv(\"mc_data_M.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df2 = pd.read_csv(\"mc_data_M.csv\")\n",
    "print(df2.head(5))\n",
    "#df3 = pd.read_csv(\"mc_test_data.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df3 = pd.read_csv(\"mc_test_data.csv\")\n",
    "print(df3.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pandas_montecarlo\n",
    "from scipy.stats import shapiro, kruskal, f_oneway\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "\n",
    "## RandomForest Classifier with monte carlo simulated training set\n",
    "numpy.random.seed(1234)\n",
    "\n",
    "#df = pd.read_csv(\"mc_test_data.csv\")\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest 0.9159663865546218\n",
      "knn 0.9243697478991597\n",
      "svc(linear) 0.8571428571428571\n",
      "svc(rbf) 0.7647058823529411\n",
      "logistic regression 0.9159663865546218\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pandas_montecarlo\n",
    "from scipy.stats import shapiro, kruskal, f_oneway\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "\n",
    "## RandomForest Classifier with monte carlo simulated training set\n",
    "numpy.random.seed(1234)\n",
    "\n",
    "#df = pd.read_csv(\"mc_test_data.csv\")\n",
    "#df = pd.read_csv(\"rndf_filt_data.csv\")\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "#random forest selected the following columns as most predictive\n",
    "df = df[['diagnosis','area_worst','concave points_mean','concave points_worst','perimeter_worst','radius_worst']]\n",
    "\n",
    "#print(df.head())\n",
    "#df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "#df = df.drop([\"Unnamed: 0\"],axis=1)\n",
    "df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "\n",
    "#split dataset for mc seed and testing\n",
    "\n",
    "df_mc, df = numpy.split(df, [int(.7*len(df))])\n",
    "\n",
    "#split dataset by class\n",
    "#df_1 = pd.read_csv(\"mc_data_M.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "#df_0 = pd.read_csv(\"mc_data_B.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df_1 = df_mc.loc[df_mc.diagnosis==1]\n",
    "df_0 = df_mc.loc[df_mc.diagnosis==0]\n",
    "df_1 = df_1.drop([\"diagnosis\"],axis=1)\n",
    "df_0 = df_0.drop([\"diagnosis\"],axis=1)\n",
    "\n",
    "#simulate class 0 data\n",
    "mc_sim_df_0 = pd.DataFrame()\n",
    "mc_sim_df_0['diagnosis']= ['0'] * len(df_0.index)\n",
    "for col in df_0.columns:\n",
    "    col_sim = df_0[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_0[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "#simulate class 1 data\n",
    "mc_sim_df_1 = pd.DataFrame()\n",
    "mc_sim_df_1['diagnosis']= ['1'] * len(df_1.index)\n",
    "for col in df_1.columns:\n",
    "    col_sim = df_1[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_1[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "\n",
    "#diag = mc_sim_df_1.append(mc_sim_df_0)['diagnosis']\n",
    "mc_sim_df = mc_sim_df_1.append(mc_sim_df_0)\n",
    "#shuffling dataframe for good luck\n",
    "#mc_sim_df = mc_sim_df.sample(frac=1)\n",
    "#mc_sim_df['diagnosis']=diag\n",
    "mc_sim_df.head(20)\n",
    "\n",
    "\n",
    "#values formatted\n",
    "labels = df[\"diagnosis\"]\n",
    "df = df.drop(\"diagnosis\",axis=1)\n",
    "dfDev, dfTes = numpy.split(df, [int(.7*len(df))])\n",
    "DDev, DTes = numpy.split(labels, [int(.7*len(labels))])\n",
    "\n",
    "DTrn =  mc_sim_df['diagnosis']\n",
    "dfTrn = mc_sim_df.drop(['diagnosis'], axis = 1)\n",
    "\n",
    "#run model and test\n",
    "#randomforest\n",
    "model = rfc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"random forest\", hit/len(pd))\n",
    "\n",
    "#knn\n",
    "model = knc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"knn\", hit/len(pd))\n",
    "\n",
    "#svc\n",
    "model = svc(kernel=\"linear\")\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"svc(linear)\", hit/len(pd))\n",
    "\n",
    "#svc\n",
    "model = svc(kernel=\"rbf\")\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"svc(rbf)\", hit/len(pd))\n",
    "\n",
    "#logistic regression\n",
    "model = lgr()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"logistic regression\", hit/len(pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest 0.9243697478991597\n",
      "knn 0.865546218487395\n",
      "svc(linear) 0.8907563025210085\n",
      "svc(rbf) 0.773109243697479\n",
      "logistic regression 0.8907563025210085\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pandas_montecarlo\n",
    "from scipy.stats import shapiro, kruskal, f_oneway\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.linear_model import LogisticRegression as lgr\n",
    "\n",
    "\n",
    "## RandomForest Classifier with monte carlo simulated training set\n",
    "numpy.random.seed(1234)\n",
    "\n",
    "#df = pd.read_csv(\"mc_test_data.csv\")\n",
    "#df = pd.read_csv(\"rndf_filt_data.csv\")\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "#random forest selected the following columns as most predictive\n",
    "df = df[['diagnosis','area_worst','concave points_mean','concave points_worst','perimeter_worst','radius_worst']]\n",
    "\n",
    "#print(df.head())\n",
    "#df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "#df = df.drop([\"Unnamed: 0\"],axis=1)\n",
    "df = df.replace({'diagnosis': \"M\"}, 1)\n",
    "df = df.replace({'diagnosis': \"B\"}, 0)\n",
    "\n",
    "#split dataset for mc seed and testing\n",
    "\n",
    "df_mc, df = numpy.split(df, [int(.7*len(df))])\n",
    "\n",
    "#split dataset by class\n",
    "#df_1 = pd.read_csv(\"mc_data_M.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "#df_0 = pd.read_csv(\"mc_data_B.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "df_1 = df_mc.loc[df_mc.diagnosis==1]\n",
    "df_0 = df_mc.loc[df_mc.diagnosis==0]\n",
    "df_1 = df_1.drop([\"diagnosis\"],axis=1)\n",
    "df_0 = df_0.drop([\"diagnosis\"],axis=1)\n",
    "\n",
    "#simulate class 0 data\n",
    "mc_sim_df_0 = pd.DataFrame()\n",
    "mc_sim_df_0['diagnosis']= ['0'] * len(df_0.index)\n",
    "for col in df_0.columns:\n",
    "    col_sim = df_0[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_0[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "#simulate class 1 data\n",
    "mc_sim_df_1 = pd.DataFrame()\n",
    "mc_sim_df_1['diagnosis']= ['1'] * len(df_1.index)\n",
    "for col in df_1.columns:\n",
    "    col_sim = df_1[col].montecarlo(sims = 2, bust = 0, goal = 0).data\n",
    "    col_sim = col_sim.drop([\"original\"],axis = 1)\n",
    "    for col2 in col_sim.columns:\n",
    "        mc_sim_df_1[col]=col_sim[col2]\n",
    "        #if(shapiro(mc_sim_df_1[col])[1]>0.05):\n",
    "            #print(kruskal(mc_sim_df_1[col],df_1[col]))\n",
    "        #else:\n",
    "            #print(f_oneway(mc_sim_df_1[col],df_1[col]))\n",
    "\n",
    "\n",
    "#diag = mc_sim_df_1.append(mc_sim_df_0)['diagnosis']\n",
    "mc_sim_df = mc_sim_df_1.append(mc_sim_df_0)\n",
    "#shuffling dataframe for good luck\n",
    "#mc_sim_df = mc_sim_df.sample(frac=1)\n",
    "#mc_sim_df['diagnosis']=diag\n",
    "mc_sim_df.head(20)\n",
    "\n",
    "\n",
    "#values formatted\n",
    "labels = df[\"diagnosis\"]\n",
    "df = df.drop(\"diagnosis\",axis=1)\n",
    "dfDev, dfTes = numpy.split(df, [int(.7*len(df))])\n",
    "DDev, DTes = numpy.split(labels, [int(.7*len(labels))])\n",
    "\n",
    "#DTrn =  mc_sim_df['diagnosis']\n",
    "#dfTrn = mc_sim_df.drop(['diagnosis'], axis = 1)\n",
    "DTrn =  df_mc['diagnosis']\n",
    "dfTrn = df_mc.drop(['diagnosis'], axis = 1)\n",
    "\n",
    "#run model and test\n",
    "#randomforest\n",
    "model = rfc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"random forest\", hit/len(pd))\n",
    "\n",
    "#knn\n",
    "model = knc()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"knn\", hit/len(pd))\n",
    "\n",
    "#svc\n",
    "model = svc(kernel=\"linear\")\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"svc(linear)\", hit/len(pd))\n",
    "\n",
    "#svc\n",
    "model = svc(kernel=\"rbf\")\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"svc(rbf)\", hit/len(pd))\n",
    "\n",
    "#logistic regression\n",
    "model = lgr()\n",
    "model = model.fit(dfTrn.values,DTrn)\n",
    "pd = model.predict(dfDev)\n",
    "hit = 0\n",
    "for i in range(len(pd)):\n",
    "    if(int(pd[i])==int(DDev.iloc[i])):\n",
    "        hit+=1\n",
    "print(\"logistic regression\", hit/len(pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
